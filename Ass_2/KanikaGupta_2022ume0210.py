# -*- coding: utf-8 -*-
"""ass_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BEaoK43ewp0wYbDYnlypTjuKl19bH4cA
"""

# Question3-Implementing hybrid image generation using spatial and frequency domain technique
import cv2   # tool for image processing
import matplotlib.pyplot as plt    # tool for data visaulization
import numpy as np       # tool to operate these arrays

# Spatial Domain-
# combining 2 images to create a hybrid image using spatial filtering technique
img1=cv2.imread("/content/dog.jpg", cv2.IMREAD_COLOR)    # read an image
img1=cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)    # converted bgr to rgb for display

from google.colab import drive
drive.mount('/content/drive')

img2=cv2.imread("/content/cat.jpg", cv2.IMREAD_COLOR)    # same for image 2
img2=cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)

low_pass_img1=cv2.GaussianBlur(img1, (17,17), 7)      # Blurring image 1
# Parameters: image, kernel size, sigma

plt.imshow(low_pass_img1)

blurred_img2=cv2.GaussianBlur(img2, (17,17), 7)      # same for image 2
high_pass_img2=cv2.subtract(img2, blurred_img2)            # subtracting original from blurred image 2

plt.imshow(high_pass_img2)

hybrid_image=cv2.add(low_pass_img1, high_pass_img2)      # adding low pass image 1 with high pass image 2

plt.imshow(hybrid_image)

# increase in kernal sizes and sigma lead to increase in blurring effect.

# 1. Gaussian Pyramid
# A Gaussian Pyramid is a series of images where each level is a progressively smaller (and blurred) version of the original image.

# 2. Laplacian Pyramid
# A Laplacian Pyramid is derived from the Gaussian Pyramid and represents the difference between successive levels of the Gaussian Pyramid.

# To generate Gaussian Pyramids
def generate_gaussian_pyramid(image, levels):
    gaussian_pyramid = [image]
    for _ in range(levels - 1):
        image = cv2.pyrDown(image)
        gaussian_pyramid.append(image)
    return gaussian_pyramid

# To generate Laplacian Pyramids
def generate_laplacian_pyramid(gaussian_pyramid):
    laplacian_pyramid = []
    for i in range(len(gaussian_pyramid) - 1):
        gaussian_expanded = cv2.pyrUp(gaussian_pyramid[i + 1])
        if gaussian_expanded.shape != gaussian_pyramid[i].shape:
            gaussian_expanded = cv2.resize(gaussian_expanded, (gaussian_pyramid[i].shape[1], gaussian_pyramid[i].shape[0]))
        laplacian = cv2.subtract(gaussian_pyramid[i], gaussian_expanded)
        laplacian_pyramid.append(laplacian)
    laplacian_pyramid.append(gaussian_pyramid[-1])  # Last level is the same
    return laplacian_pyramid

# Blend (merging) images using the Gaussian and Laplacian Pyramids
def blend_images_with_pyramids(img1, img2, levels):
    # Generate Gaussian pyramids
    gaussian_pyramid1 = generate_gaussian_pyramid(img1, levels)
    gaussian_pyramid2 = generate_gaussian_pyramid(img2, levels)

    # Generate Laplacian pyramids
    laplacian_pyramid1 = generate_laplacian_pyramid(gaussian_pyramid1)
    laplacian_pyramid2 = generate_laplacian_pyramid(gaussian_pyramid2)

    # Blend the Laplacian pyramids
    blended_pyramid = [cv2.addWeighted(lap1, 0.5, lap2, 0.5, 0) for lap1, lap2 in zip(laplacian_pyramid1, laplacian_pyramid2)]

    # Reconstruct the blended image
    blended_image = blended_pyramid[-1]
    for lap in reversed(blended_pyramid[:-1]):
        blended_image = cv2.pyrUp(blended_image)
        if blended_image.shape != lap.shape:
            blended_image = cv2.resize(blended_image, (lap.shape[1], lap.shape[0]))
        blended_image = cv2.add(blended_image, lap)

    return blended_image

blended_image=blend_images_with_pyramids(img1, img2, levels=4)
plt.imshow(blended_image);

# Bilateral Filters are used to preserve the edges while smoothing the image, whoch makes them useful for blending an image.
def bilateral_filter(image, d, sigma_color, sigma_space):
    return cv2.bilateralFilter(image, d, sigma_color, sigma_space)

def blend_images_with_pyramids(img1, img2, levels, bilateral_params):
    # Generate Gaussian pyramids
    gaussian_pyramid1 = generate_gaussian_pyramid(img1, levels)
    gaussian_pyramid2 = generate_gaussian_pyramid(img2, levels)

    # Apply bilateral filter to each level of Gaussian pyramids
    bilateral_gaussian_pyramid1 = [bilateral_filter(level, *bilateral_params) for level in gaussian_pyramid1]
    bilateral_gaussian_pyramid2 = [bilateral_filter(level, *bilateral_params) for level in gaussian_pyramid2]

    # Generate Laplacian pyramids from filtered Gaussian pyramids
    laplacian_pyramid1 = generate_laplacian_pyramid(bilateral_gaussian_pyramid1)
    laplacian_pyramid2 = generate_laplacian_pyramid(bilateral_gaussian_pyramid2)

    # Blend the Laplacian pyramids
    blended_pyramid = [cv2.addWeighted(lap1, 0.5, lap2, 0.5, 0) for lap1, lap2 in zip(laplacian_pyramid1, laplacian_pyramid2)]

    # Reconstruct the blended image
    blended_image_2 = blended_pyramid[-1]
    for lap in reversed(blended_pyramid[:-1]):
        blended_image_2 = cv2.pyrUp(blended_image)
        if blended_image_2.shape != lap.shape:
            blended_image_2 = cv2.resize(blended_image_2, (lap.shape[1], lap.shape[0]))
        blended_image_2 = cv2.add(blended_image_2, lap)

    return blended_image_2

blended_image_2=blend_images_with_pyramids(img1, img2, levels=5, bilateral_params=(5, 67, 69))
plt.imshow(blended_image_2)

# Frequency Domain-This method uses Fourier transforms to manipulate images in the frequency domain before blending them and then converting them back to the spatial domain.
# Steps-
# Converting both images to the frequency domain using the Fast Fourier Transform (FFT).
# Combining the low-frequency components of one image and the high-frequency components of the other image.
# Applying the inverse FFT to generate the hybrid image.

def fft_image(image):        # Defining Function to apply FFT
  fft=np.fft.fft2(image)
  return np.fft.fftshift(fft)

def ifft_image(image):       # Defining Function to apply inverse FFT
  ishift=np.fft.ifftshift(image)
  return np.fft.ifft2(ishift).real

# Function to create low-pass filter
def low_pass_filter(shape, cutoff):
    rows, cols, channels = shape
    crow, ccol = rows // 2, cols // 2
    mask = np.zeros((rows, cols), np.uint8)
    mask[crow - cutoff: crow + cutoff, ccol - cutoff: ccol + cutoff] = 1
    return mask

# Function to create high-pass filter
def high_pass_filter(shape, cutoff):
    rows, cols, channels = shape
    crow, ccol = rows // 2, cols // 2
    mask = np.ones((rows, cols), np.uint8)
    mask[crow - cutoff: crow + cutoff, ccol - cutoff: ccol + cutoff] = 0
    return mask

# Apply FFT to both images
fft_img1=fft_image(img1)
fft_img2=fft_image(img2)

# Generate low-pass and high-pass filters
cutoff = 40
low_pass_mask = low_pass_filter(img1.shape, cutoff)
high_pass_mask = high_pass_filter(img2.shape, cutoff)

# Apply filters to frequency domain representations
low_pass_img1 = fft_img1 * np.dstack([low_pass_mask] * 3) # Duplicate the mask for each color channel
high_pass_img2 = fft_img2 * np.dstack([high_pass_mask] * 3) # Duplicate the mask for each color channel

# Combine the low-pass and high-pass filtered images
combined_fft=low_pass_img1 + high_pass_img2

# Combining image back into a normal image (spatial domain) using Inverse Fourier Transform (IFFT).
# Apply inverse FFT to get the final hybrid image
hybrid_image=ifft_image(combined_fft)
plt.imshow(hybrid_image)

# Question 2- Hough Transform for circle detection
image_1=cv2.imread("/content/coins.png", cv2.IMREAD_GRAYSCALE)    # the image is loaded in grayscale, which is ideal for Hough Transform.
blurred_image_1=cv2.GaussianBlur(image_1, (9,9), 2)   # sigma=2-amount of blurring
circles=cv2.HoughCircles(blurred_image_1, cv2.HOUGH_GRADIENT, dp=1.2, minDist=20, param1=30, param2=40, minRadius=10, maxRadius=60)    # Performing Hough Transform
if circles is not None:
  circles=np.round(circles[0, :]).astype("int")   # Access the inner array with the cicle data
  output_image=cv2.cvtColor(image_1, cv2.COLOR_GRAY2BGR)
  for (x, y, r) in circles:
    cv2.circle(output_image, (x, y), r, (0, 255, 0), 4)
    cv2.circle(output_image, (x, y), 2, (0, 128, 255), 5)
plt.imshow(cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB))

#Question 1-Line Detection using Hough Transform
import cv2
import numpy as np
import matplotlib.pyplot as plt

# Step 1: Load and convert the image to grayscale
img_north = cv2.imread('north(1).jpg', cv2.IMREAD_GRAYSCALE)
img_top_view = cv2.imread('Top view(1).png', cv2.IMREAD_GRAYSCALE)

# Step 2: Apply Gaussian Blur to smooth the image and reduce noise
sigma = 1.0  # Standard deviation for Gaussian filter
blurred_north = cv2.GaussianBlur(img_north, (5, 5), sigma)
blurred_top_view = cv2.GaussianBlur(img_top_view, (5, 5), sigma)

# Step 3: Apply Laplacian of Gaussian (LoG) using cv2.Laplacian
log_north = cv2.Laplacian(blurred_north, cv2.CV_64F)
log_top_view = cv2.Laplacian(blurred_top_view, cv2.CV_64F)

# Step 4: Find zero-crossings to detect edges
def zero_crossings(log_img):
    zc = np.zeros_like(log_img)
    zc[1:-1, 1:-1] = ((log_img[1:-1, 1:-1] * log_img[2:, 1:-1] < 0) |
                      (log_img[1:-1, 1:-1] * log_img[1:-1, 2:] < 0))
    return zc

edges_north = zero_crossings(log_north)
edges_top_view = zero_crossings(log_top_view)

# Step 5: Apply 4% threshold (similar to Figure 10.22 in G&W)
threshold = 0.04 * np.max(edges_north)
strong_edges_north = np.where(edges_north > threshold, 255, 0).astype(np.uint8)

threshold = 0.04 * np.max(edges_top_view)
strong_edges_top_view = np.where(edges_top_view > threshold, 255, 0).astype(np.uint8)

# Step 6: Apply Hough Transform to detect lines
def hough_transform(edges_img):
    lines = cv2.HoughLinesP(edges_img, rho=1, theta=np.pi / 180, threshold=100, minLineLength=50, maxLineGap=10)
    line_img = np.zeros_like(edges_img)

    if lines is not None:
        for line in lines:
            x1, y1, x2, y2 = line[0]
            cv2.line(line_img, (x1, y1), (x2, y2), 255, 2)

    return line_img

lines_north = hough_transform(strong_edges_north)
lines_top_view = hough_transform(strong_edges_top_view)

# Plot the results
def plot_results(original, edges, lines, title):
    plt.figure(figsize=(12, 6))
    plt.subplot(1, 3, 1)
    plt.imshow(original, cmap='gray')
    plt.title(f'{title}: Original')

    plt.subplot(1, 3, 2)
    plt.imshow(edges, cmap='gray')
    plt.title(f'{title}: Edges (Zero-Crossing + Threshold)')

    plt.subplot(1, 3, 3)
    plt.imshow(lines, cmap='gray')
    plt.title(f'{title}: Detected Lines (Hough)')

    plt.show()

plot_results(img_north, strong_edges_north, lines_north, 'North View')
plot_results(img_top_view, strong_edges_top_view, lines_top_view, 'Top View')